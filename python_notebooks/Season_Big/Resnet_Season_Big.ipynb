{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPmfaj+wrM6M5e6JtMppa5G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"odgqcjU2zv3T","executionInfo":{"status":"ok","timestamp":1745045461862,"user_tz":420,"elapsed":4545,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}},"outputId":"a1f594ad-081d-4682-c177-ff04c53fee3a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-f86f2d0f-7859-471d-a96d-cc964129961d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f86f2d0f-7859-471d-a96d-cc964129961d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]}],"source":["from google.colab import files\n","files.upload()\n","\n","import os\n","os.makedirs(\"/root/.kaggle\", exist_ok=True)\n","!mv kaggle.json /root/.kaggle/\n","!chmod 600 /root/.kaggle/kaggle.json\n","\n"]},{"cell_type":"code","source":["# ========== 3. download and unzip the dataset ==========\n","!kaggle datasets download -d paramaggarwal/fashion-product-images-dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lfc57Gsk0FpS","executionInfo":{"status":"ok","timestamp":1745045648359,"user_tz":420,"elapsed":186495,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}},"outputId":"b8de3c86-0537-4b74-c1af-db603428caa4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset\n","License(s): MIT\n"]}]},{"cell_type":"code","source":["# Check if the file exists before attempting to open it\n","import zipfile\n","import os\n","if os.path.exists(\"fashion-product-images-dataset.zip\"):\n","    with zipfile.ZipFile(\"fashion-product-images-dataset.zip\", 'r') as zip_ref:\n","        zip_ref.extractall(\"fashion_data\")\n","else:\n","    print(\"Error: 'fashion-product-images-dataset.zip' not found. Please ensure the download was successful.\")\n","\n"],"metadata":{"id":"tMM6ByWh0KXB","executionInfo":{"status":"ok","timestamp":1745045855830,"user_tz":420,"elapsed":207468,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"/content/fashion_data/fashion-dataset/fashion-dataset/styles.csv\", on_bad_lines='skip')"],"metadata":{"id":"ZHtJmk3y0S-E","executionInfo":{"status":"ok","timestamp":1745046741507,"user_tz":420,"elapsed":117,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Get unique season labels\n","unique_labels = df['season'].dropna().unique()\n","\n","# Count of unique labels\n","num_labels = len(unique_labels)\n","\n","print(f\"Number of unique season labels: {num_labels}\")\n","print(\"Labels:\", unique_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1bUmzzi0PKE","executionInfo":{"status":"ok","timestamp":1745046742322,"user_tz":420,"elapsed":14,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}},"outputId":"461a87fd-0e6b-49ae-afa2-0f0cf9937563"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique season labels: 4\n","Labels: ['Fall' 'Summer' 'Winter' 'Spring']\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","from tqdm import tqdm\n","import pandas as pd\n","\n","\n","filtered_df = df[df['season'].notna()].copy()\n","\n","\n","root_dir = \"fashion_data_season\"\n","os.makedirs(root_dir, exist_ok=True)\n","\n","\n","season_labels = filtered_df['season'].astype(str).unique()\n","for label in season_labels:\n","    os.makedirs(os.path.join(root_dir, label), exist_ok=True)\n","\n","\n","source_dir = \"/content/fashion_data/fashion-dataset/images\"\n","for idx, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n","    img_name = row['id']\n","    label = str(row['season'])\n","\n","    src = os.path.join(source_dir, f\"{img_name}.jpg\")\n","    dst = os.path.join(root_dir, label)\n","    dst = os.path.join(dst, f\"{img_name}.jpg\")\n","\n","    if os.path.exists(src):\n","        try:\n","            shutil.copy(src, dst)\n","        except Exception as e:\n","            print(f\"‚ùå Error copying {img_name}: {e}\")\n","    else:\n","        print(f\"‚ö†Ô∏è Image not found: {src}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMtrhXw90Y-K","executionInfo":{"status":"ok","timestamp":1745047401459,"user_tz":420,"elapsed":62274,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}},"outputId":"0ed73366-3e40-47e1-c45e-fd391558d9ac"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":[" 15%|‚ñà‚ñå        | 6874/44403 [00:03<00:30, 1229.30it/s]"]},{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è Image not found: /content/fashion_data/fashion-dataset/images/39403.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|‚ñà‚ñà‚ñà‚ñã      | 16334/44403 [00:13<00:26, 1065.76it/s]"]},{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è Image not found: /content/fashion_data/fashion-dataset/images/39410.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 32399/44403 [00:34<00:12, 978.31it/s] "]},{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è Image not found: /content/fashion_data/fashion-dataset/images/39401.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 36490/44403 [00:40<00:13, 597.20it/s]"]},{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è Image not found: /content/fashion_data/fashion-dataset/images/39425.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 40056/44403 [00:48<00:10, 411.39it/s]"]},{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è Image not found: /content/fashion_data/fashion-dataset/images/12347.jpg\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44403/44403 [01:02<00:00, 713.19it/s]\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchvision.models import resnet18\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcJy7C_L0kTy","executionInfo":{"status":"ok","timestamp":1745047224155,"user_tz":420,"elapsed":9919,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}},"outputId":"f0692166-3bbf-4500-93d9-6a5647977e7d"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","\n","full_dataset = datasets.ImageFolder(\"/content/fashion_data_season\", transform=transform)\n","\n","\n","total_size = len(full_dataset)\n","train_size = int(0.7 * total_size)\n","val_size = int(0.15 * total_size)\n","test_size = total_size - train_size - val_size\n","\n","\n","train_dataset, val_dataset, test_dataset = random_split(\n","    full_dataset, [train_size, val_size, test_size],\n","    generator=torch.Generator().manual_seed(42)\n",")\n","\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=16)\n","test_loader = DataLoader(test_dataset, batch_size=16)"],"metadata":{"id":"c5VcZixs0m4Q","executionInfo":{"status":"ok","timestamp":1745047403936,"user_tz":420,"elapsed":147,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = resnet18(pretrained=True)\n","model.fc = nn.Linear(512, 4)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sp9singv0oWo","executionInfo":{"status":"ok","timestamp":1745047408381,"user_tz":420,"elapsed":843,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}},"outputId":"b5b3f805-df3a-4299-e47e-86603bb85dec"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 177MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=4, bias=True)\n",")"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)"],"metadata":{"id":"QbbGJnAF0-TY","executionInfo":{"status":"ok","timestamp":1745047410302,"user_tz":420,"elapsed":4,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import f1_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=10, class_names=None):\n","    best_f1 = 0.0\n","\n","    for epoch in range(epochs):\n","        # ---- Training ----\n","        model.train()\n","        running_loss = 0.0\n","        for images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        avg_train_loss = running_loss / len(train_loader)\n","\n","        # ---- Validation ----\n","        model.eval()\n","        val_loss = 0.0\n","        all_preds = []\n","        all_labels = []\n","\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","                _, preds = torch.max(outputs, 1)\n","                all_preds.extend(preds.cpu().numpy())\n","                all_labels.extend(labels.cpu().numpy())\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","        # ---- Save Best Model ----\n","        if f1 > best_f1:\n","            best_f1 = f1\n","            torch.save(model.state_dict(), \"best_model.pth\")\n","            print(f\"‚úÖ Best model updated at Epoch {epoch+1} | F1: {f1:.4f}\")\n","\n","        # ---- Confusion Matrix ----\n","        cm = confusion_matrix(all_labels, all_preds)\n","        plt.figure(figsize=(8, 6))\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                    xticklabels=class_names if class_names else np.unique(all_labels),\n","                    yticklabels=class_names if class_names else np.unique(all_labels))\n","        plt.xlabel('Predicted Label')\n","        plt.ylabel('True Label')\n","        plt.title(f'Confusion Matrix - Epoch {epoch+1}')\n","        plt.tight_layout()\n","        plt.savefig(f'confusion_matrix_epoch_{epoch+1}.png')\n","        plt.close()\n","\n","        # ---- Logging ----\n","        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | \"\n","              f\"Val Loss: {avg_val_loss:.4f} | F1 Score: {f1:.4f}\")\n"],"metadata":{"id":"p2MxgCDf00hB","executionInfo":{"status":"ok","timestamp":1745047425682,"user_tz":420,"elapsed":1567,"user":{"displayName":"Yuming Huang","userId":"15767444826968770544"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["train_model(\n","    model=model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    optimizer=optimizer,\n","    criterion=criterion,\n","    device=device,\n","    epochs=10\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9IfGk1o0_Lv","outputId":"d5c78391-8d55-4795-f91b-4bf5a768e714"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Best model updated at Epoch 1 | F1: 0.7268\n","Epoch 1 | Train Loss: 0.7106 | Val Loss: 0.6628 | F1 Score: 0.7268\n","‚úÖ Best model updated at Epoch 2 | F1: 0.7716\n","Epoch 2 | Train Loss: 0.5643 | Val Loss: 0.5942 | F1 Score: 0.7716\n","‚úÖ Best model updated at Epoch 3 | F1: 0.7805\n","Epoch 3 | Train Loss: 0.4511 | Val Loss: 0.5649 | F1 Score: 0.7805\n","‚úÖ Best model updated at Epoch 4 | F1: 0.7890\n","Epoch 4 | Train Loss: 0.3246 | Val Loss: 0.6519 | F1 Score: 0.7890\n","Epoch 5 | Train Loss: 0.2304 | Val Loss: 0.7747 | F1 Score: 0.7830\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, f1_score\n","import torch.nn.functional as F\n","import copy"],"metadata":{"id":"XVWQ93S71BT_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","all_preds, all_labels = [], []\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","\n","        preds = torch.argmax(outputs, dim=1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","acc = accuracy_score(all_labels, all_preds)\n","f1 = f1_score(all_labels, all_preds, average='macro')\n","print(f\"\\nüìä Test Accuracy: {acc:.4f}, F1 (macro): {f1:.4f}\")"],"metadata":{"id":"1Go6ePwf1EOz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","all_preds, all_labels = [], []\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","\n","        preds = torch.argmax(outputs, dim=1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","acc = accuracy_score(all_labels, all_preds)\n","f1 = f1_score(all_labels, all_preds, average='weighted')\n","print(f\"\\nüìä Test Accuracy: {acc:.4f}, F1 (weighted): {f1:.4f}\")"],"metadata":{"id":"2UF0ZIrj1Euu"},"execution_count":null,"outputs":[]}]}